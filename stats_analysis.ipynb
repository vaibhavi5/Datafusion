{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have the ground truth labels and predicted labels\n",
    "y_true = [...]  # Ground truth labels\n",
    "y_pred = [...]  # Predicted labels\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TN = cm[0, 0]  # True negatives\n",
    "FP = cm[0, 1]  # False positives\n",
    "FN = cm[1, 0]  # False negatives\n",
    "TP = cm[1, 1]  # True positives\n",
    "\n",
    "# Print the results\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"True Positives (TP):\", TP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats I decided to use:\n",
    "Compute metrics\n",
    "jaccard_score(y_true, y_pred, average=None)\n",
    "confusion_matrix(y_true, y_pred)\n",
    "f1_score(y_true, y_pred, average='weighted') #either weighted or micro\n",
    "precision_score(y_true, y_pred, average='weighted')\n",
    "recall_score(y_true, y_pred, average='weighted')\n",
    "target_names = ['', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "hamming_loss(y_true, y_pred)\n",
    "#precision_recall_fscore_support(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from math import *\n",
    "import torch\n",
    "num_channels = 1 #Depending if its multimodal or just fMRI \n",
    "\n",
    "class AlexNet3D_Dropout(nn.Module): #AlexNet3D_Deeper_Dropout\n",
    "    def __init__(self, num_classes=2):  #This is dependent on three way = 3, two way = 2 and regression = 1\n",
    "        super(AlexNet3D_Dropout, self).__init__() #ModuleList\n",
    "        \n",
    "        self.features = nn.Sequential(        \n",
    "            nn.Conv3d(num_channels, 64*num_channels, kernel_size=5,\n",
    "                      stride=1, padding=0, groups=num_channels), #kernel 5 and padding 0 for uni, kernel 3 and padding 1 for multi\n",
    "            nn.BatchNorm3d(64*num_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=3),\n",
    "\n",
    "            nn.Conv3d(64*num_channels, 128*num_channels, kernel_size=3,\n",
    "                      stride=1, padding=0, groups=num_channels),\n",
    "            nn.BatchNorm3d(128*num_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=3),\n",
    "\n",
    "            nn.Conv3d(128*num_channels, 192*num_channels,\n",
    "                      kernel_size=3, padding=1, groups=num_channels),\n",
    "            nn.BatchNorm3d(192*num_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(192*num_channels, 384*num_channels,\n",
    "                      kernel_size=3, padding=1, groups=num_channels),\n",
    "            nn.BatchNorm3d(384*num_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(384*num_channels, 256*num_channels,\n",
    "                      kernel_size=3, padding=1, groups=num_channels),\n",
    "            nn.BatchNorm3d(256*num_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(256*num_channels, 256*num_channels,\n",
    "                      kernel_size=3, padding=1, groups=num_channels),\n",
    "            nn.BatchNorm3d(256*num_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.MaxPool3d(kernel_size=3, stride=3)\n",
    "            nn.AdaptiveAvgPool3d([1,1,1]),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Dropout(),\n",
    "                                        nn.Linear(256*num_channels, 64),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Dropout(),\n",
    "                                        nn.Linear(64, num_classes),\n",
    "                                        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "          \n",
    "    def forward(self, x):\n",
    "        xp = self.features(x)\n",
    "        #for i, layer in enumerate(self.features):\n",
    "            #x = layer(x)\n",
    "            #print (i, x.size())\n",
    "        x = xp.view(xp.size(0), -1)\n",
    "        #print(\"final, \", x.shape)\n",
    "        x = self.classifier(x)\n",
    "        return [x, xp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([58, 1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def addPadding(input_tensor):\n",
    "    desired_size = (64, 64, 64)\n",
    "    current_size = input_tensor.shape[-3:]\n",
    "    padding = []\n",
    "    for i in range(len(current_size)):\n",
    "        diff = desired_size[i] - current_size[i]\n",
    "        pad_before = diff // 2\n",
    "        pad_after = diff - pad_before\n",
    "        padding.extend([pad_before, pad_after])\n",
    "\n",
    "    padding.extend([0] * (len(input_tensor.shape) - len(current_size) - 2))\n",
    "\n",
    "    padded_size = input_tensor.shape[:-3] + tuple(desired_size)\n",
    "    padded_image = F.pad(input_tensor, pad=padding[::-1], mode='constant', value=0)\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "input_tensor = torch.randn(58, 1, 53, 63, 52)  # Input tensor\n",
    "desired_size = (64, 64, 64)  # Desired size after padding\n",
    "\n",
    "padded_image = addPadding(input_tensor, desired_size)\n",
    "\n",
    "print(padded_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e81493da29025d983c6d04e3b9bf8a9f5c389919a754d23fc827784e9aaef791"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
